{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordfreq in /opt/homebrew/lib/python3.10/site-packages (3.0.3)\n",
      "Requirement already satisfied: langcodes>=3.0 in /opt/homebrew/lib/python3.10/site-packages (from wordfreq) (3.3.0)\n",
      "Requirement already satisfied: ftfy>=6.1 in /opt/homebrew/lib/python3.10/site-packages (from wordfreq) (6.1.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from wordfreq) (1.0.4)\n",
      "Requirement already satisfied: regex>=2021.7.6 in /opt/homebrew/lib/python3.10/site-packages (from wordfreq) (2022.9.13)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/homebrew/lib/python3.10/site-packages (from ftfy>=6.1->wordfreq) (0.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "8vW9svTE289D"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "import numpy as np\n",
    "from wordfreq import zipf_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors are only available in larger models, so let's download that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "mWDrpxDk2_r2"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "s = \"It's not about the money (only $20.15), it's about sending a message :). ðŸš€ðŸ’ŽðŸ™Œ\"\n",
    "doc = nlp(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[1]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_id(word: str):\n",
    "    return nlp.vocab.strings[word]\n",
    "\n",
    "def get_vector(word: str):\n",
    "    return nlp.vocab.vectors[get_vocab_id(word)]\n",
    "\n",
    "def get_token(word: str):\n",
    "    return nlp(word)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41661593317985535"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token(\"man\").similarity(get_token(\"king\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat cat 1.0\n",
      "cat lion 0.3854507803916931\n",
      "cat pet 0.732966423034668\n",
      "lion cat 0.3854507803916931\n",
      "lion lion 1.0\n",
      "lion pet 0.20031583309173584\n",
      "pet cat 0.732966423034668\n",
      "pet lion 0.20031583309173584\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'cat lion pet')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(t1.text,t2.text,t1.similarity(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle, castle, 1.000\n",
      "castle, king, 0.494\n",
      "castle, student, -0.021\n",
      "castle, dormitory, 0.370\n",
      "king, castle, 0.494\n",
      "king, king, 1.000\n",
      "king, student, 0.201\n",
      "king, dormitory, 0.224\n",
      "student, castle, -0.021\n",
      "student, king, 0.201\n",
      "student, student, 1.000\n",
      "student, dormitory, 0.470\n",
      "dormitory, castle, 0.370\n",
      "dormitory, king, 0.224\n",
      "dormitory, student, 0.470\n",
      "dormitory, dormitory, 1.000\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'castle king student dormitory')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(f\"{t1.text}, {t2.text}, {t1.similarity(t2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most similar words to a given vector\n",
    "Documentation https://spacy.io/api/vectors#most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(vec: np.ndarray, include_rare = False):\n",
    "    # vec = vector(word)\n",
    "\n",
    "    vocab_ids = nlp.vocab.vectors.most_similar(np.asarray([vec]), n=100)\n",
    "    words =  [nlp.vocab.strings[w] for w in vocab_ids[0][0]]\n",
    "    if include_rare:\n",
    "        return [w for w in words if get_token(w).is_alpha][0:20]\n",
    "    else:\n",
    "        return [w for w in words if get_token(w).is_alpha & (zipf_frequency(w, \"en\", wordlist='small', minimum=1)> 3)][0:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'physician',\n",
       " 'psychiatrist',\n",
       " 'doctors',\n",
       " 'dentist',\n",
       " 'nurse',\n",
       " 'pharmacist',\n",
       " 'pediatrician',\n",
       " 'surgeon',\n",
       " 'proctor',\n",
       " 'dermatologist',\n",
       " 'veterinarian',\n",
       " 'midwife',\n",
       " 'psychiatrists',\n",
       " 'therapist',\n",
       " 'neurologist',\n",
       " 'clinic',\n",
       " 'medic',\n",
       " 'Pediatrician',\n",
       " 'physicians']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king',\n",
       " 'princess',\n",
       " 'princesses',\n",
       " 'princes',\n",
       " 'prince',\n",
       " 'kings',\n",
       " 'queen',\n",
       " 'consort',\n",
       " 'Mcqueen',\n",
       " 'mcqueen',\n",
       " 'monarch',\n",
       " 'ruler',\n",
       " 'rulers',\n",
       " 'Princesses',\n",
       " 'thrones',\n",
       " 'kingdom',\n",
       " 'monarchs',\n",
       " 'throne',\n",
       " 'kingdoms',\n",
       " 'royal']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"king\") - get_vector(\"man\") + get_vector(\"girl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'pediatrician',\n",
       " 'nurse',\n",
       " 'midwife',\n",
       " 'physician',\n",
       " 'Pediatrician',\n",
       " 'dermatologist',\n",
       " 'dentist',\n",
       " 'therapist',\n",
       " 'Dermatologist',\n",
       " 'clinic',\n",
       " 'pharmacist',\n",
       " 'doctors',\n",
       " 'Midwife',\n",
       " 'pediatrics',\n",
       " 'psychiatrist',\n",
       " 'veterinarian',\n",
       " 'pediatric',\n",
       " 'neurologist',\n",
       " 'Physician']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\") - get_vector(\"man\") + get_vector(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student',\n",
       " 'campus',\n",
       " 'school',\n",
       " 'dormitory',\n",
       " 'university',\n",
       " 'castle',\n",
       " 'students',\n",
       " 'classmate',\n",
       " 'pupil',\n",
       " 'teacher',\n",
       " 'classroom',\n",
       " 'headmaster',\n",
       " 'undergraduate',\n",
       " 'college',\n",
       " 'Dormitory',\n",
       " 'undergraduates',\n",
       " 'gymnasium',\n",
       " 'schoolboy',\n",
       " 'pupils',\n",
       " 'highschool']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"castle\") - get_vector(\"royalty\") + get_vector(\"student\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokyo'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"Berlin\") - get_vector(\"Germany\") + get_vector(\"Japan\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold',\n",
       " 'colder',\n",
       " 'drier',\n",
       " 'warmer',\n",
       " 'cooler',\n",
       " 'milder',\n",
       " 'freezing',\n",
       " 'temperatures',\n",
       " 'dry',\n",
       " 'frosty',\n",
       " 'frost',\n",
       " 'temperature',\n",
       " 'temperate',\n",
       " 'damp',\n",
       " 'chilly',\n",
       " 'humid',\n",
       " 'warms',\n",
       " 'warmed',\n",
       " 'heat',\n",
       " 'Colder']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"bigger\") - get_vector(\"big\") + get_vector(\"cold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waffles'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"sushi\") - get_vector(\"Japan\") + get_vector(\"Belgium\"))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "- Library for embedding exploration: https://github.com/koaning/whatlies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nlpdemystified-preprocessing.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
